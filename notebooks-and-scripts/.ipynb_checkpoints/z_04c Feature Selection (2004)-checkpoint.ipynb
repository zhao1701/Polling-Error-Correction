{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Feature Selection (2004)\n",
    "This notebook follows the same process detailed in Feature Selection (2012), but with 2008 as the target year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix, mutual_info_score, roc_auc_score\n",
    "from helpers.machine_learning import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2, RFECV, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>congressional_district</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>final_vote</th>\n",
       "      <th>VCF0108</th>\n",
       "      <th>VCF0113</th>\n",
       "      <th>VCF0127</th>\n",
       "      <th>VCF0143</th>\n",
       "      <th>VCF0146</th>\n",
       "      <th>VCF0311</th>\n",
       "      <th>VCF0346</th>\n",
       "      <th>VCF0347</th>\n",
       "      <th>VCF0348</th>\n",
       "      <th>VCF0349</th>\n",
       "      <th>VCF0358</th>\n",
       "      <th>VCF0359</th>\n",
       "      <th>VCF0360</th>\n",
       "      <th>VCF0361</th>\n",
       "      <th>VCF0370</th>\n",
       "      <th>VCF0371</th>\n",
       "      <th>VCF0372</th>\n",
       "      <th>...</th>\n",
       "      <th>VCF0904_oh2</th>\n",
       "      <th>VCF0904_oh3</th>\n",
       "      <th>VCF1004_oh0</th>\n",
       "      <th>VCF1004_oh1</th>\n",
       "      <th>VCF1004_oh2</th>\n",
       "      <th>VCF1004_oh3</th>\n",
       "      <th>VCF1004_oh4</th>\n",
       "      <th>VCF9030_oh0</th>\n",
       "      <th>VCF9030_oh1</th>\n",
       "      <th>VCF9030_oh2</th>\n",
       "      <th>VCF9030_oh3</th>\n",
       "      <th>VCF9030_oh4</th>\n",
       "      <th>VCF9030_oh5</th>\n",
       "      <th>VCF9131_oh0</th>\n",
       "      <th>VCF9131_oh1</th>\n",
       "      <th>VCF9131_oh2</th>\n",
       "      <th>VCF9131_oh3</th>\n",
       "      <th>VCF9132_oh0</th>\n",
       "      <th>VCF9132_oh1</th>\n",
       "      <th>VCF9132_oh2</th>\n",
       "      <th>VCF9132_oh3</th>\n",
       "      <th>VCF9133_oh0</th>\n",
       "      <th>VCF9133_oh1</th>\n",
       "      <th>VCF9133_oh2</th>\n",
       "      <th>VCF9133_oh3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>MN01</td>\n",
       "      <td>MN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2886</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>MI01</td>\n",
       "      <td>MI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8959</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>IL11</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0454</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>ME02</td>\n",
       "      <td>ME</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>MA01</td>\n",
       "      <td>MA</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9270</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year   age congressional_district state  gender  weight  \\\n",
       "0           0  2000  49.0                   MN01    MN       0  1.2886   \n",
       "1           1  2000  35.0                   MI01    MI       1  0.8959   \n",
       "2           2  2000  57.0                   IL11    IL       1  1.0454   \n",
       "3           3  2000  63.0                   ME02    ME       0  0.6005   \n",
       "4           4  2000  40.0                   MA01    MA       1  1.9270   \n",
       "\n",
       "   final_vote  VCF0108  VCF0113  VCF0127  VCF0143  VCF0146  VCF0311  VCF0346  \\\n",
       "0           2      0.0        0        0      1.0      1.0      1.0      1.0   \n",
       "1           0      0.0        0        0      1.0      1.0      0.0      1.0   \n",
       "2           1      0.0        0        0      1.0      1.0      1.0      0.0   \n",
       "3           1      0.0        0        1      0.0      1.0      1.0      0.0   \n",
       "4           2      0.0        0        0      1.0      1.0      1.0      1.0   \n",
       "\n",
       "   VCF0347  VCF0348  VCF0349  VCF0358  VCF0359  VCF0360  VCF0361  VCF0370  \\\n",
       "0      1.0      0.0      0.0      0.0      1.0      0.0      1.0      1.0   \n",
       "1      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      1.0      1.0      0.0      0.0      1.0      1.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      1.0      1.0      0.0      1.0      1.0      1.0      0.0   \n",
       "\n",
       "   VCF0371  VCF0372     ...       VCF0904_oh2  VCF0904_oh3  VCF1004_oh0  \\\n",
       "0      0.0      1.0     ...               1.0          0.0          0.0   \n",
       "1      0.0      0.0     ...               1.0          0.0          0.0   \n",
       "2      1.0      1.0     ...               1.0          0.0          0.0   \n",
       "3      0.0      1.0     ...               1.0          0.0          0.0   \n",
       "4      0.0      1.0     ...               1.0          0.0          0.0   \n",
       "\n",
       "   VCF1004_oh1  VCF1004_oh2  VCF1004_oh3  VCF1004_oh4  VCF9030_oh0  \\\n",
       "0          0.0          1.0          0.0          0.0          0.0   \n",
       "1          1.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          1.0          0.0          0.0   \n",
       "3          1.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          1.0          1.0   \n",
       "\n",
       "   VCF9030_oh1  VCF9030_oh2  VCF9030_oh3  VCF9030_oh4  VCF9030_oh5  \\\n",
       "0          1.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          1.0   \n",
       "2          0.0          0.0          0.0          0.0          1.0   \n",
       "3          0.0          1.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   VCF9131_oh0  VCF9131_oh1  VCF9131_oh2  VCF9131_oh3  VCF9132_oh0  \\\n",
       "0          0.0          1.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          1.0          0.0          0.0   \n",
       "2          0.0          0.0          1.0          0.0          0.0   \n",
       "3          0.0          1.0          0.0          0.0          0.0   \n",
       "4          0.0          1.0          0.0          0.0          0.0   \n",
       "\n",
       "   VCF9132_oh1  VCF9132_oh2  VCF9132_oh3  VCF9133_oh0  VCF9133_oh1  \\\n",
       "0          0.0          1.0          0.0          0.0          1.0   \n",
       "1          0.0          1.0          0.0          0.0          1.0   \n",
       "2          1.0          0.0          0.0          0.0          0.0   \n",
       "3          1.0          0.0          0.0          0.0          0.0   \n",
       "4          1.0          0.0          0.0          0.0          1.0   \n",
       "\n",
       "   VCF9133_oh2  VCF9133_oh3  \n",
       "0          0.0          0.0  \n",
       "1          0.0          0.0  \n",
       "2          1.0          0.0  \n",
       "3          1.0          0.0  \n",
       "4          0.0          0.0  \n",
       "\n",
       "[5 rows x 403 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_csv('../data/anes_cdf_converted.csv')\n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def cv_test(X_train, y_train, preprocessing, classifiers, clf_names, scoring = 'f1', cv = 5):\n",
    "    scores = []\n",
    "    if preprocessing != None:\n",
    "        X_cv = preprocessing.fit_transform(X_train)\n",
    "    else:\n",
    "        X_cv = X_train\n",
    "    for model, name in zip(classifiers, clf_names):\n",
    "        cv_score = cross_val_score(X = X_cv, y = y_train, estimator = model, cv = cv, scoring = scoring)\n",
    "        scores.append([cv_score.mean(), cv_score.ptp(), cv_score.std()])\n",
    "    scores = pd.DataFrame(scores, columns = ['mean','range','std'])\n",
    "    scores.index = clf_names\n",
    "    return scores.sort_values(by = 'mean', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df_orig = df_orig.drop(['Unnamed: 0', 'congressional_district','state','final_vote'], axis = 1)\n",
    "\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF0734')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF0736')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF1011')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF0704')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF0710')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF0709')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF0703')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF0707')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF0708')]\n",
    "df_orig = df_orig.iloc[:, ~df_orig.columns.str.contains('VCF1011')]\n",
    "\n",
    "# Label non-voters as positive cases and voters as negative cases\n",
    "df_orig.VCF0702 = df_orig.VCF0702.apply(lambda x: 0 if x==1 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Separate training (pre-2004) and test (2004) data so that we can test the generalizability of a model trained on data from earlier years to that of a target year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = df_orig[:]\n",
    "df_train = df[df.year < 2004]\n",
    "\n",
    "todrop = ['VCF0702','year']\n",
    "X_train_orig = df_train.drop(todrop, axis = 1)\n",
    "y_train = df_train.VCF0702\n",
    "\n",
    "columns = X_train_orig.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test various classifiers on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>range</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.632860</td>\n",
       "      <td>0.103270</td>\n",
       "      <td>0.036795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.624909</td>\n",
       "      <td>0.252535</td>\n",
       "      <td>0.085224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.548718</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.028947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.532934</td>\n",
       "      <td>0.211870</td>\n",
       "      <td>0.075687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.479487</td>\n",
       "      <td>0.116795</td>\n",
       "      <td>0.043043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.426254</td>\n",
       "      <td>0.522648</td>\n",
       "      <td>0.191106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean     range       std\n",
       "Bernoulli Naive Bayes  0.632860  0.103270  0.036795\n",
       "AdaBoost               0.624909  0.252535  0.085224\n",
       "Logistic Regression    0.548718  0.081081  0.028947\n",
       "SVM                    0.532934  0.211870  0.075687\n",
       "Gaussian Naive Bayes   0.479487  0.116795  0.043043\n",
       "Random Forest          0.426254  0.522648  0.191106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = Imputer(missing_values = 'NaN', strategy = 'median')\n",
    "\n",
    "preprocessing = Pipeline([('imp',imp),('scale', Normalizer())])\n",
    "\n",
    "classifiers = [LogisticRegression(), RandomForestClassifier(), AdaBoostClassifier(),\n",
    "               BernoulliNB(), GaussianNB(), SVC()]\n",
    "clf_names = ['Logistic Regression','Random Forest', 'AdaBoost',\n",
    "             'Bernoulli Naive Bayes','Gaussian Naive Bayes', 'SVM']\n",
    "\n",
    "scores = cv_test(X_train_orig, y_train, preprocessing, classifiers, clf_names)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test effect of PCA on training data with various classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>range</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.554722</td>\n",
       "      <td>0.191851</td>\n",
       "      <td>0.069382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.551286</td>\n",
       "      <td>0.111688</td>\n",
       "      <td>0.042289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.550438</td>\n",
       "      <td>0.233696</td>\n",
       "      <td>0.082542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.452281</td>\n",
       "      <td>0.219852</td>\n",
       "      <td>0.080475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.305333</td>\n",
       "      <td>0.280420</td>\n",
       "      <td>0.106310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.215494</td>\n",
       "      <td>0.157265</td>\n",
       "      <td>0.052157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean     range       std\n",
       "Gaussian Naive Bayes   0.554722  0.191851  0.069382\n",
       "Logistic Regression    0.551286  0.111688  0.042289\n",
       "SVM                    0.550438  0.233696  0.082542\n",
       "AdaBoost               0.452281  0.219852  0.080475\n",
       "Bernoulli Naive Bayes  0.305333  0.280420  0.106310\n",
       "Random Forest          0.215494  0.157265  0.052157"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing = Pipeline([('imp', imp),('scale', Normalizer()),('pca', PCA(n_components = 200))])\n",
    "scores = cv_test(X_train_orig, y_train, preprocessing, classifiers, clf_names)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Adding new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding thermometer intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def add_thermometer_intensity(df):\n",
    "    \n",
    "    def thermometer_to_intensity(x):\n",
    "        if x == np.nan:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return abs(x - 5) ** 2\n",
    "    \n",
    "    columns_to_convert = (df.max() >= 10) & (df.min() == 0)\n",
    "    columns_to_convert[[df.columns.get_loc('VCF0114_r1'),df.columns.get_loc('VCF1015')]] = False\n",
    "    thermometer_df = df.loc[:,columns_to_convert]\n",
    "    thermometer_df = thermometer_df.applymap(thermometer_to_intensity)\n",
    "    thermometer_df.columns = thermometer_df.columns + '_int'\n",
    "    thermometer_df['int_sum_therm'] = thermometer_df.sum(axis = 1) ** 1.2\n",
    "    return pd.concat([df, thermometer_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>range</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.637497</td>\n",
       "      <td>0.046130</td>\n",
       "      <td>0.015059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.618026</td>\n",
       "      <td>0.091855</td>\n",
       "      <td>0.032005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.579163</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.041224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.504213</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.161609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.488067</td>\n",
       "      <td>0.114899</td>\n",
       "      <td>0.048315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.472080</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.049760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean     range       std\n",
       "Bernoulli Naive Bayes  0.637497  0.046130  0.015059\n",
       "AdaBoost               0.618026  0.091855  0.032005\n",
       "Logistic Regression    0.579163  0.119403  0.041224\n",
       "SVM                    0.504213  0.442857  0.161609\n",
       "Gaussian Naive Bayes   0.488067  0.114899  0.048315\n",
       "Random Forest          0.472080  0.138462  0.049760"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = add_thermometer_intensity(X_train_orig)\n",
    "preprocessing = Pipeline([('imp', Imputer(missing_values = 'NaN', strategy = 'median')),('scale', Normalizer())])\n",
    "scores = cv_test(X_train, y_train, preprocessing = preprocessing, classifiers = classifiers, clf_names = clf_names)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ordinal intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def add_ordinal_intensity(df):\n",
    "    columns_to_convert = ['VCF0803','VCF0806','VCF0830','VCF0851','VCF9014','VCF9015','VCF9039','VCF9042','VCF0301',\n",
    "                     'VCF0303','VCF0502','VCF0604','VCF0605','VCF0880a','VCF9009','VCF9045']\n",
    "    intensity_df = df.loc[:,columns_to_convert]\n",
    "    intensity_df = abs(intensity_df - (intensity_df.max() + intensity_df.min()) / 2)\n",
    "    intensity_df.columns = intensity_df.columns + '_int'\n",
    "    intensity_df['int_sum_ord'] = intensity_df.sum(axis = 1) ** 2\n",
    "    return pd.concat([df, intensity_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>range</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.623276</td>\n",
       "      <td>0.298930</td>\n",
       "      <td>0.105569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.621164</td>\n",
       "      <td>0.079174</td>\n",
       "      <td>0.027345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.555819</td>\n",
       "      <td>0.134460</td>\n",
       "      <td>0.049927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.502553</td>\n",
       "      <td>0.215873</td>\n",
       "      <td>0.076366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.488653</td>\n",
       "      <td>0.269744</td>\n",
       "      <td>0.088908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.482893</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.044669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean     range       std\n",
       "AdaBoost               0.623276  0.298930  0.105569\n",
       "Bernoulli Naive Bayes  0.621164  0.079174  0.027345\n",
       "Logistic Regression    0.555819  0.134460  0.049927\n",
       "SVM                    0.502553  0.215873  0.076366\n",
       "Random Forest          0.488653  0.269744  0.088908\n",
       "Gaussian Naive Bayes   0.482893  0.121622  0.044669"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = add_ordinal_intensity(X_train_orig)\n",
    "scores = cv_test(X_train, y_train, preprocessing, classifiers, clf_names)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Summing \"don't know\" responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def add_dk_sum(df):\n",
    "    df = df[:]\n",
    "    dk_column_index = df.columns.str.contains('dk')\n",
    "    dk_df = df.loc[:,dk_column_index]\n",
    "    df['dk_sum'] = dk_df.sum(axis = 1) ** 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>range</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.622441</td>\n",
       "      <td>0.131455</td>\n",
       "      <td>0.046716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.606321</td>\n",
       "      <td>0.193298</td>\n",
       "      <td>0.069687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.549532</td>\n",
       "      <td>0.074047</td>\n",
       "      <td>0.029227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.509203</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.103554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.478764</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.044760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.464408</td>\n",
       "      <td>0.203228</td>\n",
       "      <td>0.068475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean     range       std\n",
       "Bernoulli Naive Bayes  0.622441  0.131455  0.046716\n",
       "AdaBoost               0.606321  0.193298  0.069687\n",
       "Logistic Regression    0.549532  0.074047  0.029227\n",
       "SVM                    0.509203  0.306818  0.103554\n",
       "Gaussian Naive Bayes   0.478764  0.121622  0.044760\n",
       "Random Forest          0.464408  0.203228  0.068475"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = add_dk_sum(X_train_orig)\n",
    "scores = cv_test(X_train, y_train, preprocessing, classifiers, clf_names)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Removing features\n",
    "### First one-hot features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def drop_first_onehot(df):\n",
    "    return df.loc[:, ~df.columns.str.contains('oh0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def break_correlation(in_X, y, threshhold = 0.85, scoring = mutual_info_score):\n",
    "       \n",
    "    X = pd.DataFrame(Imputer(missing_values='NaN', strategy = 'median').fit_transform(in_X), columns = in_X.columns)\n",
    "    \n",
    "    corr_mask = abs(X.corr()) > threshhold\n",
    "    corr_list = corr_mask.sum()\n",
    "    corr_list = corr_list[corr_list > 1]\n",
    "    corr_dict = dict(corr_list)\n",
    "    \n",
    "    print('Correlated features:', len(corr_dict))\n",
    "    \n",
    "    cluster_list = []\n",
    "    while len(corr_list) > 0:\n",
    "        cluster = dict()\n",
    "        key = corr_list.index[0]\n",
    "        correlations = list(corr_mask[key][corr_mask[key]].index)\n",
    "\n",
    "        i = 1\n",
    "        while i < len(correlations):\n",
    "            key = correlations[i]\n",
    "            temp_correlations = list(corr_mask[key][corr_mask[key]].index)\n",
    "            difference = list(set(temp_correlations) - set(correlations))\n",
    "            if len(difference) != 0:\n",
    "                correlations = correlations + difference\n",
    "            i = i + 1\n",
    "            \n",
    "        for i in range(0, len(correlations)):\n",
    "            cluster[correlations[i]] = corr_dict[correlations[i]]\n",
    "            corr_dict.pop(correlations[i])\n",
    "            corr_list.pop(correlations[i])\n",
    "            \n",
    "        cluster_list.append(cluster)\n",
    "        \n",
    "    removed = []\n",
    "        \n",
    "    for cluster in cluster_list:\n",
    "        scores = dict()\n",
    "        for feature in cluster:\n",
    "            scores[feature] = scoring(X[feature], y)\n",
    "\n",
    "        while(len(cluster) > 0):\n",
    "            min_key = min(scores, key = scores.get)\n",
    "            removed.append(min_key)\n",
    "            temp_correlations = list(corr_mask[min_key][corr_mask[min_key]].index)\n",
    "            temp_correlations = list(set(temp_correlations).intersection(cluster))\n",
    "            temp_correlations.remove(min_key)\n",
    "            for each in temp_correlations:\n",
    "                if cluster[each] > 2:\n",
    "                    cluster[each] = cluster[each] - 1\n",
    "                else:\n",
    "                    cluster.pop(each)\n",
    "                    scores.pop(each)\n",
    "                                \n",
    "            cluster.pop(min_key)\n",
    "            scores.pop(min_key)\n",
    "        \n",
    "    print('Removed {} features:\\n'.format(len(removed)),removed)        \n",
    "    return in_X.drop(removed, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlated features: 50\n",
      "Removed 26 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>range</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.634529</td>\n",
       "      <td>0.040052</td>\n",
       "      <td>0.016370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.634490</td>\n",
       "      <td>0.201961</td>\n",
       "      <td>0.063956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.559425</td>\n",
       "      <td>0.074047</td>\n",
       "      <td>0.027321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.530918</td>\n",
       "      <td>0.269444</td>\n",
       "      <td>0.092739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.522423</td>\n",
       "      <td>0.153714</td>\n",
       "      <td>0.061080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.434258</td>\n",
       "      <td>0.319540</td>\n",
       "      <td>0.113391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean     range       std\n",
       "Bernoulli Naive Bayes  0.634529  0.040052  0.016370\n",
       "AdaBoost               0.634490  0.201961  0.063956\n",
       "Logistic Regression    0.559425  0.074047  0.027321\n",
       "SVM                    0.530918  0.269444  0.092739\n",
       "Gaussian Naive Bayes   0.522423  0.153714  0.061080\n",
       "Random Forest          0.434258  0.319540  0.113391"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = X_train_orig.describe().loc[:,X_train_orig.describe().loc['count',:] == 0].columns\n",
    "X_train = X_train_orig.drop(columns_to_drop, axis = 1)\n",
    "X_train = drop_first_onehot(X_train)\n",
    "X_train = break_correlation(X_train, y_train)\n",
    "scores = cv_test(X_train, y_train, preprocessing, classifiers, clf_names)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def feature_elimination(X, y, preprocessing, estimator = LogisticRegression()):\n",
    "    X = preprocessing.fit_transform(X)\n",
    "    rfecv = RFECV(estimator = estimator, step = 5, cv = StratifiedKFold(3), scoring = 'f1')\n",
    "    return rfecv.fit_transform(X, y), rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>range</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.688104</td>\n",
       "      <td>0.103541</td>\n",
       "      <td>0.040688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.665896</td>\n",
       "      <td>0.060732</td>\n",
       "      <td>0.022746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.646794</td>\n",
       "      <td>0.116143</td>\n",
       "      <td>0.041521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.642216</td>\n",
       "      <td>0.130046</td>\n",
       "      <td>0.046931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.584487</td>\n",
       "      <td>0.257996</td>\n",
       "      <td>0.109928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.557008</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.066779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean     range       std\n",
       "Bernoulli Naive Bayes  0.688104  0.103541  0.040688\n",
       "AdaBoost               0.665896  0.060732  0.022746\n",
       "Gaussian Naive Bayes   0.646794  0.116143  0.041521\n",
       "Logistic Regression    0.642216  0.130046  0.046931\n",
       "Random Forest          0.584487  0.257996  0.109928\n",
       "SVM                    0.557008  0.154545  0.066779"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train_orig\n",
    "columns = X_train.columns\n",
    "X_train, rfecv = feature_elimination(X_train, y_train, preprocessing, LogisticRegression())\n",
    "print('Number of features selected:', rfecv.n_features_)\n",
    "scores = cv_test(X_train, y_train, None, classifiers, clf_names)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlated features: 0\n",
      "Removed 0 features:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "selected_features = columns[rfecv.ranking_ == 1]\n",
    "X_rfe = break_correlation(pd.DataFrame(X_train, columns = selected_features), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.899820</td>\n",
       "      <td>VCF0302_oh2</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.342136</td>\n",
       "      <td>VCF0311</td>\n",
       "      <td>571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.164380</td>\n",
       "      <td>VCF9031</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.138243</td>\n",
       "      <td>VCF9029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.111918</td>\n",
       "      <td>VCF0223_dk</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.082310</td>\n",
       "      <td>VCF0211</td>\n",
       "      <td>36045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.985632</td>\n",
       "      <td>VCF0904_oh2</td>\n",
       "      <td>548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.968151</td>\n",
       "      <td>VCF9005</td>\n",
       "      <td>44570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.934805</td>\n",
       "      <td>VCF0302_oh5</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.917805</td>\n",
       "      <td>VCF0853</td>\n",
       "      <td>1178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.865483</td>\n",
       "      <td>VCF0228_dk</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.849665</td>\n",
       "      <td>VCF9093</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794657</td>\n",
       "      <td>VCF0415</td>\n",
       "      <td>23815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792540</td>\n",
       "      <td>VCF0146</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.704494</td>\n",
       "      <td>VCF0881</td>\n",
       "      <td>1209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.678022</td>\n",
       "      <td>VCF0514</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.641221</td>\n",
       "      <td>VCF0149_oh4</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficient      feature      sum\n",
       "14     1.899820  VCF0302_oh2    194.0\n",
       "1      1.342136      VCF0311    571.0\n",
       "3      1.164380      VCF9031     82.0\n",
       "2      1.138243      VCF9029      0.0\n",
       "5      1.111918   VCF0223_dk     43.0\n",
       "4      1.082310      VCF0211  36045.0\n",
       "16     0.985632  VCF0904_oh2    548.0\n",
       "8      0.968151      VCF9005  44570.0\n",
       "15     0.934805  VCF0302_oh5    247.0\n",
       "11     0.917805      VCF0853   1178.0\n",
       "6      0.865483   VCF0228_dk     28.0\n",
       "10     0.849665      VCF9093      0.0\n",
       "7      0.794657      VCF0415  23815.0\n",
       "0      0.792540      VCF0146    508.0\n",
       "12     0.704494      VCF0881   1209.0\n",
       "9      0.678022      VCF0514   2005.0\n",
       "13     0.641221  VCF0149_oh4    119.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_rankings = pd.concat([pd.DataFrame(lr.coef_.T), pd.DataFrame(selected_features)], axis = 1)\n",
    "feature_rankings.columns = ['coefficient','feature']\n",
    "feature_rankings.coefficient = feature_rankings.coefficient.apply(lambda x: abs(x))\n",
    "feature_rankings['sum'] = feature_rankings.feature.apply(lambda x: sum(df_train.loc[:,x].dropna()))\n",
    "feature_rankings.sort_values(by = 'coefficient', ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Classifying with VCF0713_oh4 as only feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score: 0.513703327324\n"
     ]
    }
   ],
   "source": [
    "df = df_orig[:]\n",
    "X_train = df[df.year < 2004]\n",
    "score_cv = cross_val_score(lr, X = X_train.VCF0713_oh4.reshape(-1,1), y = y_train, scoring = 'f1', cv = 10)\n",
    "print('f1-score:', score_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Classifying with everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53745708356002475"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_orig[:]\n",
    "X_train = df[df.year < 2004]\n",
    "X_train = X_train.drop(['VCF0713_oh4','VCF0713_oh3','VCF0713_oh2','VCF0713_oh1','VCF0702'], axis = 1)\n",
    "X_exp = preprocessing.fit_transform(X_train)\n",
    "score_cv = cross_val_score(lr, X = X_exp, y = y_train, scoring = 'f1', cv = 10)\n",
    "score_cv.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Testing Combinations\n",
    "\n",
    "### Optimizing feature sets for voting classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags: 00000\n",
      "Operations: []\n",
      "Number of features selected: 17\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.688104  0.103541  0.040688\n",
      "AdaBoost               0.665896  0.060732  0.022746\n",
      "Logistic Regression    0.642216  0.130046  0.046931\n",
      "SVM                    0.557008  0.154545  0.066779\n",
      "\n",
      "flags: 00001\n",
      "Correlated features: 50\n",
      "Removed 26 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n",
      "Operations: ['break correlation']\n",
      "Number of features selected: 51\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.670280  0.123509  0.046842\n",
      "Logistic Regression    0.654434  0.146269  0.049701\n",
      "AdaBoost               0.649852  0.101695  0.038895\n",
      "SVM                    0.596504  0.275158  0.092770\n",
      "\n",
      "flags: 00010\n",
      "Operations: ['drop first one-hot']\n",
      "Number of features selected: 9\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.653495  0.125874  0.043020\n",
      "Logistic Regression    0.649494  0.097523  0.032652\n",
      "AdaBoost               0.645948  0.102109  0.034122\n",
      "SVM                    0.548690  0.173480  0.070811\n",
      "\n",
      "flags: 00011\n",
      "Correlated features: 50\n",
      "Removed 26 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n",
      "Operations: ['drop first one-hot', 'break correlation']\n",
      "Number of features selected: 8\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.638925  0.136932  0.057004\n",
      "Logistic Regression    0.618141  0.066310  0.027078\n",
      "AdaBoost               0.613648  0.063343  0.026523\n",
      "SVM                    0.538422  0.096923  0.036032\n",
      "\n",
      "flags: 00100\n",
      "Operations: ['add dk sum']\n",
      "Number of features selected: 13\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.652192  0.126157  0.050000\n",
      "AdaBoost               0.638234  0.074074  0.025576\n",
      "Logistic Regression    0.627393  0.078815  0.028949\n",
      "SVM                    0.560726  0.174545  0.062804\n",
      "\n",
      "flags: 00101\n",
      "Correlated features: 50\n",
      "Removed 26 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n",
      "Operations: ['add dk sum', 'break correlation']\n",
      "Number of features selected: 22\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.699201  0.129785  0.045075\n",
      "Logistic Regression    0.686009  0.161031  0.054586\n",
      "AdaBoost               0.679012  0.138431  0.049693\n",
      "SVM                    0.566146  0.198571  0.073225\n",
      "\n",
      "flags: 00110\n",
      "Operations: ['add dk sum', 'drop first one-hot']\n",
      "Number of features selected: 35\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.681183  0.088384  0.030694\n",
      "Logistic Regression    0.664485  0.129954  0.049000\n",
      "AdaBoost               0.660028  0.098361  0.038048\n",
      "SVM                    0.603989  0.128205  0.054086\n",
      "\n",
      "flags: 00111\n",
      "Correlated features: 50\n",
      "Removed 26 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n",
      "Operations: ['add dk sum', 'drop first one-hot', 'break correlation']\n",
      "Number of features selected: 4\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.647299  0.127121  0.047307\n",
      "Logistic Regression    0.581312  0.208525  0.088907\n",
      "SVM                    0.549559  0.120690  0.050067\n",
      "AdaBoost               0.548240  0.149630  0.061776\n",
      "\n",
      "flags: 01000\n",
      "Operations: ['add ordinal intensity']\n",
      "Number of features selected: 18\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.714777  0.061475  0.021816\n",
      "Logistic Regression    0.671797  0.135441  0.050000\n",
      "AdaBoost               0.661366  0.122225  0.046810\n",
      "SVM                    0.559833  0.174545  0.068173\n",
      "\n",
      "flags: 01001\n",
      "Correlated features: 52\n",
      "Removed 27 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0301_int', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n",
      "Operations: ['add ordinal intensity', 'break correlation']\n",
      "Number of features selected: 31\n",
      "                           mean     range       std\n",
      "AdaBoost               0.692490  0.119178  0.047047\n",
      "Logistic Regression    0.683586  0.132688  0.046167\n",
      "Bernoulli Naive Bayes  0.668021  0.102045  0.037499\n",
      "SVM                    0.596374  0.176871  0.066078\n",
      "\n",
      "flags: 01010\n",
      "Operations: ['add ordinal intensity', 'drop first one-hot']\n",
      "Number of features selected: 20\n",
      "                           mean     range       std\n",
      "AdaBoost               0.685548  0.076150  0.026257\n",
      "Bernoulli Naive Bayes  0.667434  0.101687  0.032794\n",
      "Logistic Regression    0.656986  0.120699  0.044245\n",
      "SVM                    0.570217  0.205566  0.079469\n",
      "\n",
      "flags: 01011\n",
      "Correlated features: 52\n",
      "Removed 27 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0301_int', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n",
      "Operations: ['add ordinal intensity', 'drop first one-hot', 'break correlation']\n",
      "Number of features selected: 18\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.702712  0.108462  0.047189\n",
      "Logistic Regression    0.684012  0.149777  0.049524\n",
      "AdaBoost               0.674936  0.154536  0.050441\n",
      "SVM                    0.569802  0.198571  0.076222\n",
      "\n",
      "flags: 01100\n",
      "Operations: ['add ordinal intensity', 'add dk sum']\n",
      "Number of features selected: 19\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.697576  0.105391  0.037645\n",
      "AdaBoost               0.662854  0.181454  0.059861\n",
      "Logistic Regression    0.647034  0.158371  0.052647\n",
      "SVM                    0.575591  0.199859  0.072258\n",
      "\n",
      "flags: 01101\n",
      "Correlated features: 52\n",
      "Removed 27 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0301_int', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n",
      "Operations: ['add ordinal intensity', 'add dk sum', 'break correlation']\n",
      "Number of features selected: 32\n",
      "                           mean     range       std\n",
      "Logistic Regression    0.695972  0.117772  0.045600\n",
      "Bernoulli Naive Bayes  0.690323  0.181044  0.057399\n",
      "AdaBoost               0.675326  0.133144  0.047991\n",
      "SVM                    0.605092  0.207983  0.077916\n",
      "\n",
      "flags: 01110\n",
      "Operations: ['add ordinal intensity', 'add dk sum', 'drop first one-hot']\n",
      "Number of features selected: 21\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.685649  0.092857  0.033037\n",
      "AdaBoost               0.671675  0.104116  0.035944\n",
      "Logistic Regression    0.670955  0.114604  0.044389\n",
      "SVM                    0.562670  0.231322  0.079057\n",
      "\n",
      "flags: 01111\n",
      "Correlated features: 52\n",
      "Removed 27 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0301_int', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2']\n",
      "Operations: ['add ordinal intensity', 'add dk sum', 'drop first one-hot', 'break correlation']\n",
      "Number of features selected: 19\n",
      "                           mean     range       std\n",
      "AdaBoost               0.688832  0.083085  0.029177\n",
      "Bernoulli Naive Bayes  0.688350  0.065728  0.024004\n",
      "Logistic Regression    0.681200  0.060168  0.022973\n",
      "SVM                    0.575135  0.146446  0.061599\n",
      "\n",
      "flags: 10000\n",
      "Operations: ['add thermometer intensity']\n",
      "Number of features selected: 10\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.644881  0.158673  0.054600\n",
      "Logistic Regression    0.595424  0.123933  0.044732\n",
      "AdaBoost               0.594989  0.109091  0.043795\n",
      "SVM                    0.544247  0.205566  0.075719\n",
      "\n",
      "flags: 10001\n",
      "Correlated features: 52\n",
      "Removed 27 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2', 'VCF0424_int']\n",
      "Operations: ['add thermometer intensity', 'break correlation']\n",
      "Number of features selected: 13\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.674619  0.060721  0.019634\n",
      "AdaBoost               0.672731  0.063636  0.024429\n",
      "Logistic Regression    0.641797  0.093975  0.032412\n",
      "SVM                    0.553225  0.174545  0.074071\n",
      "\n",
      "flags: 10010\n",
      "Operations: ['add thermometer intensity', 'drop first one-hot']\n",
      "Number of features selected: 17\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.707298  0.112935  0.040623\n",
      "AdaBoost               0.681424  0.132934  0.046961\n",
      "Logistic Regression    0.680619  0.101754  0.041538\n",
      "SVM                    0.579005  0.231166  0.079223\n",
      "\n",
      "flags: 10011\n",
      "Correlated features: 52\n",
      "Removed 27 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2', 'VCF0424_int']\n",
      "Operations: ['add thermometer intensity', 'drop first one-hot', 'break correlation']\n",
      "Number of features selected: 20\n",
      "                           mean     range       std\n",
      "Logistic Regression    0.698587  0.133127  0.045574\n",
      "AdaBoost               0.698470  0.109524  0.049124\n",
      "Bernoulli Naive Bayes  0.693497  0.134615  0.049087\n",
      "SVM                    0.542311  0.180650  0.074328\n",
      "\n",
      "flags: 10100\n",
      "Operations: ['add thermometer intensity', 'add dk sum']\n",
      "Number of features selected: 21\n",
      "                           mean     range       std\n",
      "AdaBoost               0.678992  0.125000  0.045780\n",
      "Bernoulli Naive Bayes  0.676881  0.177226  0.063533\n",
      "Logistic Regression    0.667824  0.086727  0.032371\n",
      "SVM                    0.544377  0.159041  0.063180\n",
      "\n",
      "flags: 10101\n",
      "Correlated features: 52\n",
      "Removed 27 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2', 'VCF0424_int']\n",
      "Operations: ['add thermometer intensity', 'add dk sum', 'break correlation']\n",
      "Number of features selected: 19\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.714359  0.093897  0.032524\n",
      "AdaBoost               0.690799  0.129954  0.044690\n",
      "Logistic Regression    0.677746  0.103715  0.040068\n",
      "SVM                    0.561718  0.164068  0.069648\n",
      "\n",
      "flags: 10110\n",
      "Operations: ['add thermometer intensity', 'add dk sum', 'drop first one-hot']\n",
      "Number of features selected: 8\n",
      "                           mean     range       std\n",
      "AdaBoost               0.669944  0.074303  0.027558\n",
      "Bernoulli Naive Bayes  0.665486  0.060721  0.021319\n",
      "Logistic Regression    0.647111  0.079424  0.025512\n",
      "SVM                    0.544279  0.159041  0.061468\n",
      "\n",
      "flags: 10111\n",
      "Correlated features: 52\n",
      "Removed 27 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2', 'VCF0424_int']\n",
      "Operations: ['add thermometer intensity', 'add dk sum', 'drop first one-hot', 'break correlation']\n",
      "Number of features selected: 16\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.719531  0.062151  0.021772\n",
      "AdaBoost               0.669620  0.111142  0.040455\n",
      "Logistic Regression    0.647858  0.142320  0.051338\n",
      "SVM                    0.556707  0.174545  0.068662\n",
      "\n",
      "flags: 11000\n",
      "Operations: ['add thermometer intensity', 'add ordinal intensity']\n",
      "Number of features selected: 16\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.695763  0.103846  0.045390\n",
      "Logistic Regression    0.682055  0.128087  0.045511\n",
      "AdaBoost               0.681166  0.168215  0.054266\n",
      "SVM                    0.576520  0.224138  0.081044\n",
      "\n",
      "flags: 11001\n",
      "Correlated features: 54\n",
      "Removed 28 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0301_int', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2', 'VCF0424_int']\n",
      "Operations: ['add thermometer intensity', 'add ordinal intensity', 'break correlation']\n",
      "Number of features selected: 33\n",
      "                           mean     range       std\n",
      "AdaBoost               0.677856  0.205711  0.075873\n",
      "Bernoulli Naive Bayes  0.669676  0.081111  0.029722\n",
      "Logistic Regression    0.666810  0.148366  0.054736\n",
      "SVM                    0.600774  0.130952  0.048206\n",
      "\n",
      "flags: 11010\n",
      "Operations: ['add thermometer intensity', 'add ordinal intensity', 'drop first one-hot']\n",
      "Number of features selected: 28\n",
      "                           mean     range       std\n",
      "Logistic Regression    0.686639  0.121246  0.043330\n",
      "AdaBoost               0.683847  0.109469  0.049957\n",
      "Bernoulli Naive Bayes  0.668111  0.139726  0.045424\n",
      "SVM                    0.595330  0.138365  0.056061\n",
      "\n",
      "flags: 11011\n",
      "Correlated features: 54\n",
      "Removed 28 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0301_int', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2', 'VCF0424_int']\n",
      "Operations: ['add thermometer intensity', 'add ordinal intensity', 'drop first one-hot', 'break correlation']\n",
      "Number of features selected: 10\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.683354  0.100000  0.038932\n",
      "AdaBoost               0.674365  0.106248  0.036397\n",
      "Logistic Regression    0.656046  0.105263  0.048811\n",
      "SVM                    0.544391  0.183957  0.068797\n",
      "\n",
      "flags: 11100\n",
      "Operations: ['add thermometer intensity', 'add ordinal intensity', 'add dk sum']\n",
      "Number of features selected: 22\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.704038  0.073059  0.030404\n",
      "AdaBoost               0.688812  0.105932  0.034825\n",
      "Logistic Regression    0.667226  0.084839  0.034168\n",
      "SVM                    0.579636  0.168768  0.063829\n",
      "\n",
      "flags: 11101\n",
      "Correlated features: 54\n",
      "Removed 28 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0301_int', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2', 'VCF0424_int']\n",
      "Operations: ['add thermometer intensity', 'add ordinal intensity', 'add dk sum', 'break correlation']\n",
      "Number of features selected: 14\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.715282  0.094009  0.032882\n",
      "AdaBoost               0.667101  0.106248  0.040395\n",
      "Logistic Regression    0.648115  0.128079  0.049092\n",
      "SVM                    0.546207  0.174545  0.067704\n",
      "\n",
      "flags: 11110\n",
      "Operations: ['add thermometer intensity', 'add ordinal intensity', 'add dk sum', 'drop first one-hot']\n",
      "Number of features selected: 9\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.677707  0.111705  0.045012\n",
      "AdaBoost               0.663228  0.076280  0.025554\n",
      "Logistic Regression    0.660847  0.065391  0.021338\n",
      "SVM                    0.540386  0.214545  0.074548\n",
      "\n",
      "flags: 11111\n",
      "Correlated features: 54\n",
      "Removed 28 features:\n",
      " ['VCF0107_oh5', 'VCF0105a_oh5', 'VCF0112_oh2', 'VCF0127', 'VCF0450', 'VCF0904_oh1', 'VCF9030a', 'VCF0211_dk', 'VCF0429_dk', 'VCF0424', 'VCF0624', 'VCF0114_r1', 'VCF0504_dk', 'VCF0514_dk', 'VCF0541_dk', 'VCF0550_dk', 'VCF0804_dk', 'VCF0803_dk', 'VCF0804', 'VCF0110', 'VCF0303', 'VCF0301_int', 'VCF0870', 'VCF0714_oh2', 'VCF9131_oh2', 'VCF9132_oh1', 'VCF9133_oh2', 'VCF0424_int']\n",
      "Operations: ['add thermometer intensity', 'add ordinal intensity', 'add dk sum', 'drop first one-hot', 'break correlation']\n",
      "Number of features selected: 16\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.703391  0.114410  0.043268\n",
      "AdaBoost               0.696541  0.110766  0.038450\n",
      "Logistic Regression    0.684764  0.091226  0.036371\n",
      "SVM                    0.585705  0.191950  0.068930\n",
      "\n",
      "best f1 for Logistic Regression is 0.7195314562302743 with combination: ['add thermometer intensity', 'add dk sum', 'drop first one-hot', 'break correlation']\n",
      "best f1 for AdaBoost is 0.6984704973660687 with combination: ['add thermometer intensity', 'drop first one-hot', 'break correlation']\n",
      "best f1 for Bernoulli Naive Bayes is 0.6934965034965035 with combination: ['add thermometer intensity', 'drop first one-hot', 'break correlation']\n",
      "best f1 for SVM is 0.6050917141049967 with combination: ['add ordinal intensity', 'add dk sum', 'break correlation']\n"
     ]
    }
   ],
   "source": [
    "max_f1 = [0,0,0,0]\n",
    "best_config = [0,0,0,0]\n",
    "X_train_features = [0,0,0,0]\n",
    "\n",
    "classifiers = [LogisticRegression(), AdaBoostClassifier(), BernoulliNB(), SVC()]\n",
    "clf_names = ['Logistic Regression', 'AdaBoost', 'Bernoulli Naive Bayes', 'SVM']\n",
    "\n",
    "for i in range(0, 32):\n",
    "    columns_to_drop = X_train_orig.describe().loc[:,X_train_orig.describe().loc['count',:] == 0].columns\n",
    "    X_train = X_train_orig.drop(columns_to_drop, axis = 1)\n",
    "    operations = []\n",
    "    flags = '{:05d}'.format(int(bin(i)[2:]))\n",
    "    print('flags:', flags)\n",
    "    if int(flags[0]):\n",
    "        X_train = add_thermometer_intensity(X_train)\n",
    "        operations.append('add thermometer intensity')\n",
    "    if int(flags[1]):\n",
    "        X_train = add_ordinal_intensity(X_train)\n",
    "        operations.append('add ordinal intensity')\n",
    "    if int(flags[2]):\n",
    "        X_train = add_dk_sum(X_train)\n",
    "        operations.append('add dk sum')\n",
    "    if int(flags[3]):        \n",
    "        X_train = drop_first_onehot(X_train)\n",
    "        operations.append('drop first one-hot')\n",
    "    if int(flags[4]):\n",
    "        columns_to_drop = X_train.describe().loc[:,X_train.describe().loc['count',:] == 0].columns\n",
    "        X_train = X_train.drop(columns_to_drop, axis = 1)\n",
    "        X_train = break_correlation(X_train, y_train)\n",
    "        operations.append('break correlation')\n",
    "    columns = X_train.columns\n",
    "    X_train, rfecv = feature_elimination(X_train, y_train, preprocessing, LogisticRegression())\n",
    "    print('Operations:', operations)\n",
    "    print('Number of features selected:', rfecv.n_features_)\n",
    "    scores = cv_test(X_train, y_train, None, classifiers, clf_names, cv = 5)\n",
    "    print(scores.sort_values(by = 'mean', ascending = False))\n",
    "    \n",
    "    selected_features = columns[rfecv.ranking_ == 1]\n",
    "    for i in range(0,4):\n",
    "        if max_f1[i] < scores['mean'][i]:\n",
    "            max_f1[i] = scores['mean'][i]\n",
    "            best_config[i] = operations\n",
    "            X_train_features[i] = selected_features\n",
    "    print('')\n",
    "\n",
    "for f1, config, name in zip(max_f1, best_config, clf_names):\n",
    "    print('best f1 for {} is {} with combination: {}'.format(name, f1, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        mean    range       std\n",
      "Logistic Regression  0.64055  0.54902  0.131831 \n",
      "\n",
      "              mean     range       std\n",
      "AdaBoost  0.687163  0.310924  0.102909 \n",
      "\n",
      "                           mean     range       std\n",
      "Bernoulli Naive Bayes  0.699026  0.292292  0.087139 \n",
      "\n",
      "         mean     range       std\n",
      "SVM  0.592865  0.512987  0.141275 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_all = add_dk_sum(add_thermometer_intensity(add_ordinal_intensity(X_train_orig)))\n",
    "X_train_config = [0,0,0,0]\n",
    "for i in range(0, len(X_train_config)):\n",
    "    X_train_config[i] = X_train_all.loc[:,X_train_features[i]]\n",
    "\n",
    "print(cv_test(X_train_config[0], y_train, preprocessing, [LogisticRegression()], ['Logistic Regression'], cv = 10),'\\n')\n",
    "print(cv_test(X_train_config[1], y_train, preprocessing, [AdaBoostClassifier()], ['AdaBoost'], cv = 10),'\\n')\n",
    "print(cv_test(X_train_config[2], y_train, preprocessing, [BernoulliNB()], ['Bernoulli Naive Bayes'], cv = 10),'\\n')\n",
    "print(cv_test(X_train_config[3], y_train, preprocessing, [SVC()], ['SVM'], cv = 10),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 16)\n",
      "(718, 20)\n",
      "(718, 20)\n",
      "(718, 32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(X_train_config)):\n",
    "    print(X_train_config[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_config[0].to_csv('../data/anes_cdf_training_2004_lr.csv')\n",
    "X_train_config[1].to_csv('../data/anes_cdf_training_2004_ada.csv')\n",
    "X_train_config[2].to_csv('../data/anes_cdf_training_2004_bnb.csv')\n",
    "X_train_config[3].to_csv('../data/anes_cdf_training_2004_svm.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
